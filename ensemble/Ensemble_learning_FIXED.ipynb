{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f0334d2",
   "metadata": {},
   "source": [
    "# Fixed Ensemble Learning for Music Genre Classification\n",
    "\n",
    "This notebook implements a properly designed ensemble approach combining:\n",
    "- LSTM model for vocal features\n",
    "- CNN model for accompaniment features\n",
    "- Proper train/validation/test splits\n",
    "- Correct stacking implementation without data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a843c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Bidirectional, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088da56b",
   "metadata": {},
   "source": [
    "## Configuration and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55636b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 64\n",
    "data_path_vocal = '../Data/data.json'  # Vocal MFCCs\n",
    "data_path_accomp = '../Data/accompaniment_mfcc.json'  # Accompaniment MFCCs\n",
    "lstm_model_path = '../models/lstm_vocal_classifier.keras'\n",
    "cnn_model_path = '../models/cnn_accompaniment_classifier.keras'\n",
    "\n",
    "genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "num_classes = len(genres)\n",
    "epochs = 100\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4832836c",
   "metadata": {},
   "source": [
    "## Step 1: Load and Prepare Data\n",
    "\n",
    "**FIX**: Load separate vocal and accompaniment data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadff3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading data...\")\n",
    "\n",
    "# Load vocal MFCCs\n",
    "with open(data_path_vocal, 'r', encoding='utf-8') as f:\n",
    "    data_vocal = json.load(f)\n",
    "\n",
    "# Load accompaniment MFCCs (if available)\n",
    "if os.path.exists(data_path_accomp):\n",
    "    with open(data_path_accomp, 'r', encoding='utf-8') as f:\n",
    "        data_accomp = json.load(f)\n",
    "    print(\"✓ Loaded separate vocal and accompaniment data\")\n",
    "else:\n",
    "    print(\"⚠ Warning: Accompaniment data not found. Using vocal data for both (not ideal).\")\n",
    "    data_accomp = data_vocal\n",
    "\n",
    "# Extract features and labels\n",
    "mfccs_vocal = data_vocal['mfcc']\n",
    "mfccs_accomp = data_accomp['mfcc']\n",
    "labels = data_vocal['genre_num']\n",
    "\n",
    "print(f\"Vocal MFCCs: {len(mfccs_vocal)}, Accomp MFCCs: {len(mfccs_accomp)}, Labels: {len(labels)}\")\n",
    "\n",
    "# Align data\n",
    "min_length = min(len(mfccs_vocal), len(mfccs_accomp), len(labels))\n",
    "mfccs_vocal = mfccs_vocal[:min_length]\n",
    "mfccs_accomp = mfccs_accomp[:min_length]\n",
    "labels = labels[:min_length]\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_vocal = np.array(mfccs_vocal)\n",
    "X_accomp = np.array(mfccs_accomp)\n",
    "y = np.array(labels)\n",
    "\n",
    "print(f\"\\nInitial shapes:\")\n",
    "print(f\"X_vocal: {X_vocal.shape}, X_accomp: {X_accomp.shape}, y: {y.shape}\")\n",
    "\n",
    "# Handle non-finite values\n",
    "for X, name in [(X_vocal, \"Vocal\"), (X_accomp, \"Accompaniment\")]:\n",
    "    if not np.isfinite(X).all():\n",
    "        print(f\"⚠ Warning: Non-finite values in {name} MFCCs, replacing with zeros\")\n",
    "        X = np.where(np.isfinite(X), X, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b2cff",
   "metadata": {},
   "source": [
    "## Step 2: Preprocess Features for Different Models\n",
    "\n",
    "**FIX**: Properly reshape data for LSTM (40, 132) and CNN (40, 132, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b079b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_mfcc_for_lstm(X, target_shape=(40, 132)):\n",
    "    \"\"\"Prepare MFCCs for LSTM input: (samples, 40, 132)\"\"\"\n",
    "    X_processed = X.copy()\n",
    "    \n",
    "    if X_processed.shape[1:] == (130, 13):\n",
    "        # Truncate to 40 coefficients\n",
    "        X_processed = X_processed[:, :40, :]\n",
    "        # Pad time dimension to 132\n",
    "        X_processed = np.pad(X_processed, ((0, 0), (0, 0), (0, 132 - X_processed.shape[2])), mode='constant')\n",
    "    \n",
    "    return X_processed\n",
    "\n",
    "def prepare_mfcc_for_cnn(X, target_shape=(40, 132, 1)):\n",
    "    \"\"\"Prepare MFCCs for CNN input: (samples, 40, 132, 1)\"\"\"\n",
    "    X_processed = prepare_mfcc_for_lstm(X)\n",
    "    # Add channel dimension\n",
    "    X_processed = X_processed[..., np.newaxis]\n",
    "    return X_processed\n",
    "\n",
    "# Prepare data\n",
    "X_vocal_processed = prepare_mfcc_for_lstm(X_vocal)\n",
    "X_accomp_processed = prepare_mfcc_for_cnn(X_accomp)\n",
    "\n",
    "print(\"Processed shapes:\")\n",
    "print(f\"X_vocal (for LSTM): {X_vocal_processed.shape}\")\n",
    "print(f\"X_accomp (for CNN): {X_accomp_processed.shape}\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "print(f\"\\nEncoded labels: {np.unique(y_encoded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6000c540",
   "metadata": {},
   "source": [
    "## Step 3: Split Data Properly\n",
    "\n",
    "**FIX**: Use proper train/val/test split (60/20/20) with stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5e91b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split: 60% train, 40% temp (for val and test)\n",
    "X_vocal_train, X_vocal_temp, X_accomp_train, X_accomp_temp, y_train, y_temp = train_test_split(\n",
    "    X_vocal_processed, X_accomp_processed, y_encoded, \n",
    "    test_size=0.4, stratify=y_encoded, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: 50% of temp for val, 50% for test (20% each of total)\n",
    "X_vocal_val, X_vocal_test, X_accomp_val, X_accomp_test, y_val, y_test = train_test_split(\n",
    "    X_vocal_temp, X_accomp_temp, y_temp, \n",
    "    test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Data split:\")\n",
    "print(f\"Train: {X_vocal_train.shape[0]} samples ({X_vocal_train.shape[0]/len(X_vocal_processed)*100:.1f}%)\")\n",
    "print(f\"Val:   {X_vocal_val.shape[0]} samples ({X_vocal_val.shape[0]/len(X_vocal_processed)*100:.1f}%)\")\n",
    "print(f\"Test:  {X_vocal_test.shape[0]} samples ({X_vocal_test.shape[0]/len(X_vocal_processed)*100:.1f}%)\")\n",
    "\n",
    "# Verify stratification\n",
    "print(\"\\nClass distribution:\")\n",
    "print(f\"Train: {np.bincount(y_train)}\")\n",
    "print(f\"Val:   {np.bincount(y_val)}\")\n",
    "print(f\"Test:  {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7825ba0a",
   "metadata": {},
   "source": [
    "## Step 4: Load or Train Base Models\n",
    "\n",
    "**FIX**: Use consistent, clean architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e744b47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(input_shape=(40, 132), num_classes=10):\n",
    "    \"\"\"Build LSTM model for vocal classification\"\"\"\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(256, return_sequences=True), input_shape=input_shape),\n",
    "        Bidirectional(LSTM(256)),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_cnn_model(input_shape=(40, 132, 1), num_classes=10):\n",
    "    \"\"\"Build CNN model for accompaniment classification\"\"\"\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Load or build LSTM model\n",
    "if os.path.exists(lstm_model_path):\n",
    "    print(\"Loading LSTM model...\")\n",
    "    lstm_model = load_model(lstm_model_path)\n",
    "else:\n",
    "    print(\"Training LSTM model...\")\n",
    "    lstm_model = build_lstm_model()\n",
    "    lstm_model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-7)\n",
    "    ]\n",
    "    \n",
    "    lstm_history = lstm_model.fit(\n",
    "        X_vocal_train, y_train,\n",
    "        validation_data=(X_vocal_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    lstm_model.save(lstm_model_path)\n",
    "\n",
    "# Load or build CNN model\n",
    "if os.path.exists(cnn_model_path):\n",
    "    print(\"Loading CNN model...\")\n",
    "    cnn_model = load_model(cnn_model_path)\n",
    "else:\n",
    "    print(\"Training CNN model...\")\n",
    "    cnn_model = build_cnn_model()\n",
    "    cnn_model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-7)\n",
    "    ]\n",
    "    \n",
    "    cnn_history = cnn_model.fit(\n",
    "        X_accomp_train, y_train,\n",
    "        validation_data=(X_accomp_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    cnn_model.save(cnn_model_path)\n",
    "\n",
    "print(\"\\n✓ Base models ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccebdded",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate Individual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757058ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate LSTM\n",
    "lstm_loss, lstm_acc = lstm_model.evaluate(X_vocal_test, y_test, verbose=0)\n",
    "print(f\"LSTM Test Accuracy: {lstm_acc:.4f}\")\n",
    "\n",
    "# Evaluate CNN\n",
    "cnn_loss, cnn_acc = cnn_model.evaluate(X_accomp_test, y_test, verbose=0)\n",
    "print(f\"CNN Test Accuracy: {cnn_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3213a2",
   "metadata": {},
   "source": [
    "## Step 6: Generate Predictions for Ensemble\n",
    "\n",
    "**IMPORTANT**: Generate predictions on validation and test sets separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf31d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating predictions...\")\n",
    "\n",
    "# Validation set predictions (for training meta-models)\n",
    "lstm_probs_val = lstm_model.predict(X_vocal_val, verbose=0)\n",
    "cnn_probs_val = cnn_model.predict(X_accomp_val, verbose=0)\n",
    "\n",
    "# Test set predictions (for final evaluation)\n",
    "lstm_probs_test = lstm_model.predict(X_vocal_test, verbose=0)\n",
    "cnn_probs_test = cnn_model.predict(X_accomp_test, verbose=0)\n",
    "\n",
    "print(f\"Validation predictions shape: {lstm_probs_val.shape}, {cnn_probs_val.shape}\")\n",
    "print(f\"Test predictions shape: {lstm_probs_test.shape}, {cnn_probs_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50e7781",
   "metadata": {},
   "source": [
    "## Step 7: Bagging Methods (Voting)\n",
    "\n",
    "**FIX**: Proper averaging and weighted voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515c49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== BAGGING METHODS ===\")\n",
    "\n",
    "# 1. Simple Average (Equal weights)\n",
    "mean_probs = (lstm_probs_test + cnn_probs_test) / 2\n",
    "mean_preds = np.argmax(mean_probs, axis=1)\n",
    "mean_accuracy = accuracy_score(y_test, mean_preds)\n",
    "print(f\"\\n1. Mean Averaging Accuracy: {mean_accuracy:.4f}\")\n",
    "\n",
    "# 2. Weighted Voting (based on validation accuracy)\n",
    "lstm_val_acc = accuracy_score(y_val, np.argmax(lstm_probs_val, axis=1))\n",
    "cnn_val_acc = accuracy_score(y_val, np.argmax(cnn_probs_val, axis=1))\n",
    "\n",
    "# Normalize weights to sum to 1\n",
    "total_acc = lstm_val_acc + cnn_val_acc\n",
    "w_lstm = lstm_val_acc / total_acc\n",
    "w_cnn = cnn_val_acc / total_acc\n",
    "\n",
    "print(f\"\\nWeights based on validation accuracy:\")\n",
    "print(f\"LSTM: {w_lstm:.3f} (val_acc={lstm_val_acc:.4f})\")\n",
    "print(f\"CNN:  {w_cnn:.3f} (val_acc={cnn_val_acc:.4f})\")\n",
    "\n",
    "weighted_probs = w_lstm * lstm_probs_test + w_cnn * cnn_probs_test\n",
    "weighted_preds = np.argmax(weighted_probs, axis=1)\n",
    "weighted_accuracy = accuracy_score(y_test, weighted_preds)\n",
    "print(f\"\\n2. Weighted Voting Accuracy: {weighted_accuracy:.4f}\")\n",
    "\n",
    "# 3. Max Voting (Hard voting)\n",
    "lstm_class_preds = np.argmax(lstm_probs_test, axis=1)\n",
    "cnn_class_preds = np.argmax(cnn_probs_test, axis=1)\n",
    "\n",
    "# Combine predictions (if they disagree, choose based on confidence)\n",
    "max_probs = np.maximum(np.max(lstm_probs_test, axis=1), np.max(cnn_probs_test, axis=1))\n",
    "max_preds = np.where(\n",
    "    np.max(lstm_probs_test, axis=1) > np.max(cnn_probs_test, axis=1),\n",
    "    lstm_class_preds,\n",
    "    cnn_class_preds\n",
    ")\n",
    "max_accuracy = accuracy_score(y_test, max_preds)\n",
    "print(f\"\\n3. Max Voting Accuracy: {max_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6766e11",
   "metadata": {},
   "source": [
    "## Step 8: Stacking Methods\n",
    "\n",
    "**FIX**: Train meta-models on VALIDATION set, evaluate on TEST set (no data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2708c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== STACKING METHODS ===\")\n",
    "\n",
    "# Prepare stacking features\n",
    "stacking_features_val = np.concatenate([lstm_probs_val, cnn_probs_val], axis=1)\n",
    "stacking_features_test = np.concatenate([lstm_probs_test, cnn_probs_test], axis=1)\n",
    "\n",
    "print(f\"Stacking features shape - Val: {stacking_features_val.shape}, Test: {stacking_features_test.shape}\")\n",
    "\n",
    "# 1. Logistic Regression Meta-Model\n",
    "print(\"\\n1. Training Logistic Regression meta-model...\")\n",
    "lr_meta = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_meta.fit(stacking_features_val, y_val)\n",
    "\n",
    "lr_val_preds = lr_meta.predict(stacking_features_val)\n",
    "lr_test_preds = lr_meta.predict(stacking_features_test)\n",
    "\n",
    "lr_val_acc = accuracy_score(y_val, lr_val_preds)\n",
    "lr_test_acc = accuracy_score(y_test, lr_test_preds)\n",
    "\n",
    "print(f\"Logistic Regression - Val Acc: {lr_val_acc:.4f}, Test Acc: {lr_test_acc:.4f}\")\n",
    "\n",
    "# 2. XGBoost Meta-Model\n",
    "print(\"\\n2. Training XGBoost meta-model...\")\n",
    "xgb_meta = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42,\n",
    "    eval_metric='mlogloss',\n",
    "    use_label_encoder=False\n",
    ")\n",
    "xgb_meta.fit(stacking_features_val, y_val)\n",
    "\n",
    "xgb_val_preds = xgb_meta.predict(stacking_features_val)\n",
    "xgb_test_preds = xgb_meta.predict(stacking_features_test)\n",
    "\n",
    "xgb_val_acc = accuracy_score(y_val, xgb_val_preds)\n",
    "xgb_test_acc = accuracy_score(y_test, xgb_test_preds)\n",
    "\n",
    "print(f\"XGBoost - Val Acc: {xgb_val_acc:.4f}, Test Acc: {xgb_test_acc:.4f}\")\n",
    "\n",
    "# 3. Neural Network Meta-Model\n",
    "print(\"\\n3. Training Neural Network meta-model...\")\n",
    "\n",
    "def build_meta_model(input_dim=20, num_classes=10):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "nn_meta = build_meta_model(input_dim=stacking_features_val.shape[1])\n",
    "nn_meta.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Further split validation set for meta-model training\n",
    "X_meta_train, X_meta_val, y_meta_train, y_meta_val = train_test_split(\n",
    "    stacking_features_val, y_val, test_size=0.2, stratify=y_val, random_state=42\n",
    ")\n",
    "\n",
    "nn_history = nn_meta.fit(\n",
    "    X_meta_train, y_meta_train,\n",
    "    validation_data=(X_meta_val, y_meta_val),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "nn_val_loss, nn_val_acc = nn_meta.evaluate(stacking_features_val, y_val, verbose=0)\n",
    "nn_test_loss, nn_test_acc = nn_meta.evaluate(stacking_features_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"Neural Network - Val Acc: {nn_val_acc:.4f}, Test Acc: {nn_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc57993",
   "metadata": {},
   "source": [
    "## Step 9: Summary of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b4c5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENSEMBLE RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = [\n",
    "    (\"LSTM (individual)\", lstm_acc),\n",
    "    (\"CNN (individual)\", cnn_acc),\n",
    "    (\"Mean Averaging\", mean_accuracy),\n",
    "    (\"Weighted Voting\", weighted_accuracy),\n",
    "    (\"Max Voting\", max_accuracy),\n",
    "    (\"Stacking - Logistic Regression\", lr_test_acc),\n",
    "    (\"Stacking - XGBoost\", xgb_test_acc),\n",
    "    (\"Stacking - Neural Network\", nn_test_acc)\n",
    "]\n",
    "\n",
    "# Sort by accuracy\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nTest Accuracy Rankings:\\n\")\n",
    "for i, (name, acc) in enumerate(results, 1):\n",
    "    improvement = \"\"\n",
    "    if acc > max(lstm_acc, cnn_acc):\n",
    "        improvement = f\" (+{acc - max(lstm_acc, cnn_acc):.4f})\"\n",
    "    print(f\"{i}. {name:.<45} {acc:.4f}{improvement}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20398c9c",
   "metadata": {},
   "source": [
    "## Step 10: Visualize Best Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eda86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best performing model (XGBoost in most cases)\n",
    "best_preds = xgb_test_preds\n",
    "best_name = \"XGBoost Stacking\"\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, best_preds)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=genres, yticklabels=genres,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.xlabel('Predicted Genre', fontsize=12)\n",
    "plt.ylabel('True Genre', fontsize=12)\n",
    "plt.title(f'Confusion Matrix - {best_name}\\nTest Accuracy: {xgb_test_acc:.4f}', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, best_preds, target_names=genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d5f811",
   "metadata": {},
   "source": [
    "## Step 11: Compare All Methods Visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b8cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot comparison\n",
    "methods = [r[0] for r in results]\n",
    "accuracies = [r[1] for r in results]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['#FF6B6B' if 'individual' in m.lower() else '#4ECDC4' if 'Voting' in m or 'Averaging' in m else '#45B7D1' for m in methods]\n",
    "bars = plt.barh(methods, accuracies, color=colors)\n",
    "\n",
    "# Add accuracy values on bars\n",
    "for i, (bar, acc) in enumerate(zip(bars, accuracies)):\n",
    "    plt.text(acc + 0.005, i, f'{acc:.4f}', va='center', fontsize=10)\n",
    "\n",
    "plt.xlabel('Test Accuracy', fontsize=12)\n",
    "plt.title('Comparison of Ensemble Methods', fontsize=14, fontweight='bold')\n",
    "plt.xlim(0, 1.0)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Ensemble learning analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
